{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c79a0f6-d664-4221-96d7-227b61482887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset saved as 'cms_with_income_and_location.csv'\n",
      "                MEDICAL CENTER NAME                 ADDRESS    CITY STATE  \\\n",
      "0  Southeast Alabama Medical Center  1108 Ross Clark Circle  Dothan    AL   \n",
      "1  Southeast Alabama Medical Center  1108 Ross Clark Circle  Dothan    AL   \n",
      "2  Southeast Alabama Medical Center  1108 Ross Clark Circle  Dothan    AL   \n",
      "3  Southeast Alabama Medical Center  1108 Ross Clark Circle  Dothan    AL   \n",
      "4  Southeast Alabama Medical Center  1108 Ross Clark Circle  Dothan    AL   \n",
      "\n",
      "     ZIP                                        PROCEDURE  \\\n",
      "0  36301  Level 2 Excision/ Biopsy/ Incision and Drainage   \n",
      "1  36301  Level 2 Excision/ Biopsy/ Incision and Drainage   \n",
      "2  36301  Level 2 Excision/ Biopsy/ Incision and Drainage   \n",
      "3  36301  Level 2 Excision/ Biopsy/ Incision and Drainage   \n",
      "4  36301  Level 2 Excision/ Biopsy/ Incision and Drainage   \n",
      "\n",
      "   Avg_Tot_Sbmtd_Chrgs  Avg_Mdcr_Alowd_Amt  Avg_Mdcr_Pymt_Amt      Source  \\\n",
      "0          9575.005714         1038.454672         826.277954  Outpatient   \n",
      "1          9575.005714         1038.454672         826.277954  Outpatient   \n",
      "2          9575.005714         1038.454672         826.277954  Outpatient   \n",
      "3          9575.005714         1038.454672         826.277954  Outpatient   \n",
      "4          9575.005714         1038.454672         826.277954  Outpatient   \n",
      "\n",
      "   Households Median Income (Dollars)  Households Mean Income (Dollars)  \\\n",
      "0                             43054.0                           62415.0   \n",
      "1                             42045.0                           60659.0   \n",
      "2                             42140.0                           58856.0   \n",
      "3                             40702.0                           56374.0   \n",
      "4                             39618.0                           53650.0   \n",
      "\n",
      "        lat       lng    city state_name  population  \n",
      "0  31.14387 -85.40321  Dothan    Alabama     38627.0  \n",
      "1  31.14387 -85.40321  Dothan    Alabama     38627.0  \n",
      "2  31.14387 -85.40321  Dothan    Alabama     38627.0  \n",
      "3  31.14387 -85.40321  Dothan    Alabama     38627.0  \n",
      "4  31.14387 -85.40321  Dothan    Alabama     38627.0  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Step 2: Load all datasets (local paths assumed)\n",
    "cms_df = pd.read_excel(\"cms_data.xlsx\")  # Cleaned CMS data\n",
    "income_df = pd.read_csv(\"us_income_zipcode.csv\", encoding='latin1')\n",
    "zip_df = pd.read_csv(\"uszips.csv\", encoding='latin1')\n",
    "\n",
    "# Step 3: Standardize ZIP code formatting for merging\n",
    "cms_df['ZIP'] = cms_df['ZIP'].astype(str).str.zfill(5)\n",
    "income_df['ZIP'] = income_df['ZIP'].astype(str).str.zfill(5)\n",
    "zip_df.rename(columns={'zip': 'ZIP'}, inplace=True)\n",
    "zip_df['ZIP'] = zip_df['ZIP'].astype(str).str.zfill(5)\n",
    "\n",
    "# Step 4: Select relevant columns for merging\n",
    "income_df = income_df[['ZIP', 'Households Median Income (Dollars)', 'Households Mean Income (Dollars)']]\n",
    "zip_df = zip_df[['ZIP', 'lat', 'lng', 'city', 'state_name', 'population']]\n",
    "\n",
    "# Step 5: Merge all datasets together on ZIP code\n",
    "merged_df = cms_df.merge(income_df, on='ZIP', how='left')\n",
    "merged_df = merged_df.merge(zip_df, on='ZIP', how='left')\n",
    "\n",
    "# Step 6: Save the cleaned and merged dataset\n",
    "merged_df.to_csv(\"cms_with_income_and_location.csv\", index=False)\n",
    "\n",
    "# Step 7: Preview merged dataset\n",
    "print(\"Merged dataset saved as 'cms_with_income_and_location.csv'\")\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "145dae8b-7a4f-4cdc-a016-9f54de550266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset saved as 'cms_with_income_and_location.csv'\n",
      "     ZIP                                        PROCEDURE  Avg_Mdcr_Pymt_Amt  \\\n",
      "0  36301  Level 2 Excision/ Biopsy/ Incision and Drainage         826.277954   \n",
      "1  36301  Level 2 Excision/ Biopsy/ Incision and Drainage         826.277954   \n",
      "2  36301  Level 2 Excision/ Biopsy/ Incision and Drainage         826.277954   \n",
      "3  36301  Level 2 Excision/ Biopsy/ Incision and Drainage         826.277954   \n",
      "4  36301  Level 2 Excision/ Biopsy/ Incision and Drainage         826.277954   \n",
      "\n",
      "   Households Median Income (Dollars)  Affordability_Score  \n",
      "0                             43054.0             0.019192  \n",
      "1                             42045.0             0.019652  \n",
      "2                             42140.0             0.019608  \n",
      "3                             40702.0             0.020301  \n",
      "4                             39618.0             0.020856  \n"
     ]
    }
   ],
   "source": [
    "# Step 6: Create Affordability Score (lower is better)\n",
    "merged_df['Affordability_Score'] = merged_df['Avg_Mdcr_Pymt_Amt'] / merged_df['Households Median Income (Dollars)']\n",
    "\n",
    "# Step 7: Save the cleaned and merged dataset with score\n",
    "merged_df.to_csv(\"cms_with_income_and_location.csv\", index=False)\n",
    "\n",
    "# Step 8: Preview merged dataset\n",
    "print(\"Merged dataset saved as 'cms_with_income_and_location.csv'\")\n",
    "print(merged_df[['ZIP', 'PROCEDURE', 'Avg_Mdcr_Pymt_Amt', 'Households Median Income (Dollars)', 'Affordability_Score']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81aa73f8-765f-4011-8018-30921578d43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from fuzzywuzzy import fuzz\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5870c49-2563-4a00-a23a-a056586e4290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /opt/anaconda3/lib/python3.12/site-packages (4.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (0.31.1)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "zsh:1: command not found: python-Levenshtein\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers\n",
    "!python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "062d38e7-6b99-472b-90c2-6ec45920d3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:21: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:21: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/var/folders/qt/xn0rf1j15x3d_8zjxwk7w5_40000gn/T/ipykernel_19183/367870561.py:21: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  model_df.columns = model_df.columns.str.replace('[\\s\\(\\)]', '_', regex=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1785\n",
      "[LightGBM] [Info] Number of data points in the train set: 3083782, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 4451.498006\n",
      "LightGBM MAE on test set: $65.61\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 2: Load merged dataset\n",
    "merged_df = pd.read_csv(\"cms_with_income_and_location.csv\", low_memory=False)\n",
    "\n",
    "# Step 3: Prepare data for model\n",
    "# Drop rows with missing target or key features\n",
    "model_df = merged_df.dropna(subset=['Avg_Mdcr_Pymt_Amt', 'ZIP', 'PROCEDURE', 'Households Median Income (Dollars)', 'population'])\n",
    "\n",
    "# Drop leakage-prone features\n",
    "model_df = model_df.drop(columns=['Avg_Mdcr_Alowd_Amt', 'Avg_Tot_Sbmtd_Chrgs'], errors='ignore')\n",
    "\n",
    "# Clean column names to remove spaces and parentheses\n",
    "model_df.columns = model_df.columns.str.replace('[\\s\\(\\)]', '_', regex=True)\n",
    "\n",
    "# Keep only numeric and boolean columns\n",
    "model_df = model_df.select_dtypes(include=[np.number, 'bool']).copy()\n",
    "\n",
    "# Step 4: Select features and target\n",
    "target = 'Avg_Mdcr_Pymt_Amt'\n",
    "features = [col for col in model_df.columns if col != target]\n",
    "X = model_df[features]\n",
    "y = model_df[target]\n",
    "\n",
    "# Step 5: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Train LightGBM model with optimized hyperparameters\n",
    "model = lgb.LGBMRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=64,\n",
    "    max_depth=10,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"LightGBM MAE on test set: ${mae:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "400b5e54-f4bc-43e3-8aa0-56e669758e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Medicare Payment for typical ZIP profile: $5100.32\n",
      "Predicted Medicare Payment for ZIP 10001: $4588.89\n",
      "Top 5 Cheapest ZIPs for User Profile:\n",
      "        ZIP  Households Median Income (Dollars)  \\\n",
      "2838  94403                            103612.0   \n",
      "2833  94115                             97090.0   \n",
      "2834  94117                            122266.0   \n",
      "2835  94133                             55098.0   \n",
      "2836  94304                            104831.0   \n",
      "\n",
      "      Households Mean Income (Dollars)  population  Affordability_Score  \\\n",
      "2838                          132788.0     43459.0             0.026351   \n",
      "2833                          147143.0     32715.0             0.088874   \n",
      "2834                          161068.0     37575.0             0.044786   \n",
      "2835                          102837.0     24753.0             0.052863   \n",
      "2836                          176181.0      4731.0             0.012593   \n",
      "\n",
      "      Predicted_Cost  \n",
      "2838     4028.083811  \n",
      "2833     4028.083811  \n",
      "2834     4028.083811  \n",
      "2835     4028.083811  \n",
      "2836     4028.083811  \n"
     ]
    }
   ],
   "source": [
    "# Step 8: Predict for a new example\n",
    "# Define an example with mean values for context\n",
    "example_input = X.mean().to_frame().T\n",
    "example_prediction = model.predict(example_input)[0]\n",
    "print(f\"Predicted Medicare Payment for typical ZIP profile: ${example_prediction:.2f}\")\n",
    "\n",
    "# Step 9: Define custom prediction function\n",
    "# Use mean values from training data to ensure same shape\n",
    "mean_input = X.mean()\n",
    "\n",
    "def predict_cost(zip_val, median_income, mean_income, pop, affordability):\n",
    "    input_data = mean_input.copy()\n",
    "    input_data['ZIP'] = zip_val\n",
    "    input_data['Households_Median_Income_Dollars'] = median_income\n",
    "    input_data['Households_Mean_Income_Dollars'] = mean_income\n",
    "    input_data['population'] = pop\n",
    "    input_data['Affordability_Score'] = affordability\n",
    "    input_df = pd.DataFrame([input_data])[X.columns]  # Align with training features\n",
    "    return model.predict(input_df)[0]\n",
    "\n",
    "# Example prediction\n",
    "cost = predict_cost(zip_val=10001, median_income=60000, mean_income=70000, pop=50000, affordability=0.08)\n",
    "print(f\"Predicted Medicare Payment for ZIP 10001: ${cost:.2f}\")\n",
    "\n",
    "# Step 10: Top 5 cheapest ZIPs for user profile\n",
    "# Group by ZIP and calculate median features\n",
    "grouped = merged_df.groupby(\"ZIP\")[[\n",
    "    \"Households Median Income (Dollars)\",\n",
    "    \"Households Mean Income (Dollars)\",\n",
    "    \"population\",\n",
    "    \"Affordability_Score\"\n",
    "]].median().dropna().reset_index()\n",
    "\n",
    "def batch_predict(df):\n",
    "    predictions = []\n",
    "    for _, row in df.iterrows():\n",
    "        pred = predict_cost(\n",
    "            zip_val=row['ZIP'],\n",
    "            median_income=row['Households Median Income (Dollars)'],\n",
    "            mean_income=row['Households Mean Income (Dollars)'],\n",
    "            pop=row['population'],\n",
    "            affordability=row['Affordability_Score']\n",
    "        )\n",
    "        predictions.append(pred)\n",
    "    df['Predicted_Cost'] = predictions\n",
    "    return df\n",
    "\n",
    "user_income = 65000\n",
    "user_mean_income = 75000\n",
    "user_pop = 40000\n",
    "user_afford = 0.07\n",
    "\n",
    "zip_group = merged_df.groupby(\"ZIP\")[[\n",
    "    \"Households Median Income (Dollars)\",\n",
    "    \"Households Mean Income (Dollars)\",\n",
    "    \"population\",\n",
    "    \"Affordability_Score\"\n",
    "]].median().dropna().reset_index()\n",
    "\n",
    "zip_group['Predicted_Cost'] = zip_group.apply(\n",
    "    lambda row: predict_cost(\n",
    "        zip_val=row['ZIP'],\n",
    "        median_income=user_income,\n",
    "        mean_income=user_mean_income,\n",
    "        pop=user_pop,\n",
    "        affordability=user_afford\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "zip_predictions_sorted = zip_group.sort_values(\"Predicted_Cost\")\n",
    "print(\"Top 5 Cheapest ZIPs for User Profile:\")\n",
    "print(zip_predictions_sorted.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "385ff3ed-0ae2-4075-beba-62d0b6546164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopandas\n",
      "  Downloading geopandas-1.0.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: numpy>=1.22 in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (1.26.4)\n",
      "Collecting pyogrio>=0.7.2 (from geopandas)\n",
      "  Downloading pyogrio-0.11.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (24.1)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (2.2.2)\n",
      "Collecting pyproj>=3.3.0 (from geopandas)\n",
      "  Downloading pyproj-3.7.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (31 kB)\n",
      "Collecting shapely>=2.0.0 (from geopandas)\n",
      "  Downloading shapely-2.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2023.3)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from pyogrio>=0.7.2->geopandas) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.16.0)\n",
      "Downloading geopandas-1.0.1-py3-none-any.whl (323 kB)\n",
      "Downloading pyogrio-0.11.0-cp312-cp312-macosx_12_0_arm64.whl (19.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyproj-3.7.1-cp312-cp312-macosx_14_0_arm64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.1.0-cp312-cp312-macosx_11_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: shapely, pyproj, pyogrio, geopandas\n",
      "Successfully installed geopandas-1.0.1 pyogrio-0.11.0 pyproj-3.7.1 shapely-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install geopandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "71699c69-429d-4c56-ae69-a67390775e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 00:11:25.030 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /opt/anaconda3/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 11: Streamlit interactive visualization with filters and overlays\n",
    "import streamlit as st\n",
    "import pydeck as pdk\n",
    "\n",
    "st.title(\"Medicare Cost Prediction Map\")\n",
    "\n",
    "# Sidebar filters\n",
    "user_income = st.sidebar.slider(\"Median Income\", 20000, 150000, 65000)\n",
    "user_mean_income = st.sidebar.slider(\"Mean Income\", 25000, 200000, 75000)\n",
    "user_pop = st.sidebar.slider(\"Population\", 1000, 1000000, 40000)\n",
    "user_afford = st.sidebar.slider(\"Affordability Score\", 0.01, 0.5, 0.07)\n",
    "\n",
    "# Recalculate predictions based on inputs\n",
    "zip_group['Predicted_Cost'] = zip_group.apply(\n",
    "    lambda row: predict_cost(\n",
    "        zip_val=row['ZIP'],\n",
    "        median_income=user_income,\n",
    "        mean_income=user_mean_income,\n",
    "        pop=user_pop,\n",
    "        affordability=user_afford\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "# Prepare merged map data\n",
    "zip_latlng = merged_df[['ZIP', 'lat', 'lng']].dropna().drop_duplicates()\n",
    "zip_latlng['ZIP'] = zip_latlng['ZIP'].astype(str).str.zfill(5)\n",
    "zip_group['ZIP'] = zip_group['ZIP'].astype(str).str.zfill(5)\n",
    "map_df = pd.merge(zip_group, zip_latlng, on='ZIP', how='left').dropna(subset=['lat', 'lng'])\n",
    "\n",
    "st.subheader(\"Top 5 Cheapest ZIPs\")\n",
    "st.dataframe(map_df.sort_values(\"Predicted_Cost\").head())\n",
    "\n",
    "# Create interactive map\n",
    "st.subheader(\"Predicted Medicare Costs Map\")\n",
    "st.pydeck_chart(pdk.Deck(\n",
    "    map_style='mapbox://styles/mapbox/light-v9',\n",
    "    initial_view_state=pdk.ViewState(\n",
    "        latitude=37.5,\n",
    "        longitude=-95.0,\n",
    "        zoom=3.5,\n",
    "        pitch=0,\n",
    "    ),\n",
    "    layers=[\n",
    "        pdk.Layer(\n",
    "            'ScatterplotLayer',\n",
    "            data=map_df,\n",
    "            get_position='[lng, lat]',\n",
    "            get_color='[255 - (Predicted_Cost - 4000)/5, 100, 140]',\n",
    "            get_radius=25000,\n",
    "            pickable=True\n",
    "        )\n",
    "    ],\n",
    "    tooltip={\"text\": \"ZIP: {ZIP}\\nCost: ${Predicted_Cost:.2f}\"}\n",
    "))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
